# Import necessary modules
from langchain_openai import ChatOpenAI  # For using OpenAI-compatible models (like LLaMA via OpenRouter)
from langchain_anthropic import ChatAnthropic  # (Not used in this code, can be removed if unused)
from dotenv import load_dotenv  # To load API keys from .env file
from langchain_core.prompts import PromptTemplate  # For creating structured prompts
from langchain_core.output_parsers import StrOutputParser  # For parsing outputs as strings
from langchain.schema.runnable import RunnableParallel, RunnableBranch, RunnableLambda  # For building chains and branching logic
from langchain_core.output_parsers import PydanticOutputParser  # To parse outputs into Pydantic models
from pydantic import BaseModel, Field  # For defining output schema
from typing import Literal  # For fixed string literals like "positive" or "negative"

# Load environment variables (e.g., API keys)
load_dotenv()

# Initialize the LLaMA model (served via OpenRouter in this case)
model = ChatOpenAI(model='meta-llama/llama-3.3-70b-instruct')

# Output parser to just return plain string (used later for final response generation)
parser = StrOutputParser()

# Define a Pydantic class to structure model output for sentiment classification
class Feedback(BaseModel):
    sentiment: Literal['positive', 'negative'] = Field(description='Give the sentiment of the feedback')

# Create a parser that will enforce the above Pydantic schema on model output
parser2 = PydanticOutputParser(pydantic_object=Feedback)

# Prompt template for classifying feedback sentiment
prompt1 = PromptTemplate(
    template='Classify the sentiment of the following feedback text into postive or negative \n {feedback} \n {format_instruction}',
    input_variables=['feedback'],  # Input: user feedback
    partial_variables={'format_instruction': parser2.get_format_instructions()}  # Inject formatting instructions auto-generated by parser2
)

# Create a chain to classify feedback using prompt1 → model → structured output parser
classifier_chain = prompt1 | model | parser2

# Prompt template for generating response to **positive** feedback
prompt2 = PromptTemplate(
    template='Write an appropriate response to this positive feedback \n {feedback}',
    input_variables=['feedback']
)

# Prompt template for generating response to **negative** feedback
prompt3 = PromptTemplate(
    template='Write an appropriate response to this negative feedback \n {feedback}',
    input_variables=['feedback']
)

# Branch logic based on sentiment:
# If sentiment is 'positive', run prompt2 → model → output as string
# If sentiment is 'negative', run prompt3 → model → output as string
# Otherwise, return fallback message
branch_chain = RunnableBranch(
    (lambda x: x.sentiment == 'positive', prompt2 | model | parser),
    (lambda x: x.sentiment == 'negative', prompt3 | model | parser),
    RunnableLambda(lambda x: "could not find sentiment")  # Fallback if no condition matches
)

# Final chain: classify sentiment first, then generate a proper response accordingly
chain = classifier_chain | branch_chain

# Run the entire chain with a sample feedback
print(chain.invoke({'feedback': 'This is a beautiful phone'}))  # Should detect positive and generate a suitable reply

# Visualize the internal flow of the chain (useful for debugging or understanding chain steps)
chain.get_graph().print_ascii()
